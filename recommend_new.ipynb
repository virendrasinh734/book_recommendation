{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/virendrasinh734/book_recommendation/blob/main/recommend_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB9d-O5jh7EG"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYx0AodOiA_T",
        "outputId": "2f716d52-1d60-49a1-973d-8b45413ee3c2"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4xcCUNLiFq9"
      },
      "outputs": [],
      "source": [
        "df_books = pd.read_csv(\n",
        "    'BX-Books.csv',\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    'BX-Book-Ratings.csv',\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFW5Ztc2iImV",
        "outputId": "b157d6a0-e506-4d1d-8229-c5ef1b862c71"
      },
      "outputs": [],
      "source": [
        "print(df_books.shape)\n",
        "print(df_ratings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j40Mdq05iMQT"
      },
      "outputs": [],
      "source": [
        "user_review_counts = df_ratings['user'].value_counts()\n",
        "\n",
        "book_review_counts = df_ratings['isbn'].value_counts()\n",
        "\n",
        "user_review_counts = df_ratings['user'].value_counts()\n",
        "popular_users = user_review_counts[user_review_counts > 100].index\n",
        "book_review_counts = df_ratings['isbn'].value_counts()\n",
        "popular_books = book_review_counts[book_review_counts > 10].index\n",
        "\n",
        "filtered_ratings = df_ratings[\n",
        "    (df_ratings['user'].isin(popular_users)) &\n",
        "    (df_ratings['isbn'].isin(popular_books))\n",
        "]\n",
        "final_data = filtered_ratings.merge(df_books, on='isbn')\n",
        "final_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1tIn6HdNdvI",
        "outputId": "2c7b7d95-618f-4f38-cfe3-3fc91ec08247"
      },
      "outputs": [],
      "source": [
        "titles=final_data['title']\n",
        "tr=titles.drop_duplicates()\n",
        "tr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "-AfDeiSoiSmd",
        "outputId": "0edc59a2-133e-4b28-c160-73c7eda628fd"
      },
      "outputs": [],
      "source": [
        "table=final_data.pivot_table(index='title',columns='user',values='rating')\n",
        "table.fillna(0,inplace=True)\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IZN95bPbTk5",
        "outputId": "092d566e-68e8-4a00-f665-5ab70e335c5a"
      },
      "outputs": [],
      "source": [
        "book_titles = table.index.tolist()\n",
        "print(len(book_titles))\n",
        "isbn_list = []\n",
        "title_to_isbn={}\n",
        "for title in book_titles:\n",
        "    matching_isbns = df_books[df_books['title'] == title]['isbn'].tolist()\n",
        "    title_to_isbn[title]=matching_isbns\n",
        "    isbn_list.append(matching_isbns)\n",
        "\n",
        "print(len(isbn_list))\n",
        "print(len(list(title_to_isbn.keys())))\n",
        "# with open(\"isbn_names.txt\",\"w\") as file:\n",
        "#     for item in isbn_list:\n",
        "#         file.write(f\"{item}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('title_to_isbn_mapping.json', 'w') as json_file:\n",
        "    json.dump(title_to_isbn, json_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zpNc4M3bvT8",
        "outputId": "7850c305-1824-460a-f0fe-5023dee07c19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVzVRuiwNdvJ",
        "outputId": "4ec0cbd9-6d6c-48d6-aae1-edd95419cda2"
      },
      "outputs": [],
      "source": [
        "table.shape\n",
        "table.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLnk8RYSzuOl"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database (create a new database if it doesn't exist)\n",
        "conn = sqlite3.connect('my_database.db')\n",
        "\n",
        "# Create a new table 'titles_table' in the database with a column 'title'\n",
        "tr.to_sql('titles', conn, if_exists='replace', index=False, dtype={'title': 'TEXT'})\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YMICPxbNdvL"
      },
      "outputs": [],
      "source": [
        "def get_db_connection():\n",
        "    conn = sqlite3.connect('my_database.db')\n",
        "    return conn\n",
        "\n",
        "def get_book_titles():\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('SELECT title FROM table_name')\n",
        "    titles = [row[0] for row in cursor.fetchall()]\n",
        "    conn.close()\n",
        "    return titles\n",
        "titles2 = get_book_titles()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_XO2_Idi2Xl",
        "outputId": "d192bac2-0f1a-405e-809b-c088285cf1e0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "cosine_sim_matrix = cosine_similarity(table, table)\n",
        "book_A_index = 2330  \n",
        "similarities_to_book_A = cosine_sim_matrix[book_A_index]\n",
        "sorted_indices = similarities_to_book_A.argsort()[::-1]  \n",
        "top_similar_books = [book for book in sorted_indices if book != book_A_index][:5]  # Exclude book A and select the top 5 similar books\n",
        "\n",
        "print(top_similar_books)\n",
        "print(cosine_sim_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import json\n",
        "\n",
        "data_dir = \"./ddeess\"\n",
        "with open(\"ind_to_book.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
        "    ind_to_book = json.load(json_file)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = text.lower().split()\n",
        "    return tokens\n",
        "\n",
        "documents = []\n",
        "file_paths = [os.path.join(data_dir, f\"{i}.txt\") for i in range(13629)]\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        description = file.read()\n",
        "        tokens = preprocess_text(description)  \n",
        "        tag = os.path.basename(file_path).split(\".\")[0]\n",
        "        print(tag)\n",
        "        book_title = ind_to_book[tag]\n",
        "        # print(book_title)\n",
        "        tokens.append(book_title)\n",
        "        document = TaggedDocument(words=tokens, tags=[tag])\n",
        "        documents.append(document)\n",
        "\n",
        "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=30)\n",
        "model.build_vocab(documents)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "book_vectors = [model.dv[f\"{i}\"] for i in range(13629)]\n",
        "\n",
        "cosine_mat = cosine_similarity(book_vectors, book_vectors)\n",
        "\n",
        "print(cosine_mat.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "cosine_sim_matrix_user = np.array(cosine_sim_matrix)\n",
        "cosine_sim_matrix_description = np.array(cosine_mat)\n",
        "\n",
        "weight_user_reviews = 0.7\n",
        "weight_book_description = 0.3\n",
        "\n",
        "combined_cosine_sim_matrix = (weight_user_reviews * cosine_sim_matrix_user) + (weight_book_description * cosine_sim_matrix_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('combined_cosine_sim_matrix.pkl', 'wb') as file:\n",
        "    pickle.dump(combined_cosine_sim_matrix, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7_2wzjVjIct"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# pickle.dump(table,open('./pickle_files/table.pkl','wb'))\n",
        "# pickle.dump(cosine_sim_matrix,open('./pickle_files/cosine_sim.pkl','wb'))\n",
        "# def get_recommends(book):\n",
        "#   ind=np.where(table.index==book)[0][0]\n",
        "#   temp=indices[ind]\n",
        "#   rc=[]\n",
        "#   for i in range(len(temp)):\n",
        "\n",
        "#     b=table.iloc[temp[i]].name\n",
        "#     # temp_df=df_books[df_books['title']==b]\n",
        "#     # temp_df.drop_duplicates('title')['title']\n",
        "#     s=closeness[ind][i]\n",
        "#     t2=[b]\n",
        "#     rc.append(b)\n",
        "#   recommended_books=[rc]\n",
        "#   return recommended_books\n",
        "# books = get_recommends(\"Anna Karenina\")\n",
        "# print(books)\n",
        "# import pickle\n",
        "# pickle.dump(table,open('./pickle_files/table.pkl','wb'))\n",
        "# pickle.dump(indices,open('./pickle_files/indices.pkl','wb'))\n",
        "# pickle.dump(closeness,open('./pickle_files/closeness.pkl','wb'))\n",
        "# booksdb = pd.read_csv(\n",
        "#     books_filename,\n",
        "#     encoding = \"ISO-8859-1\",\n",
        "#     sep=\";\",\n",
        "#     header=0,\n",
        "#     names=['isbn', 'title', 'author','y','p','img2','img'],\n",
        "#     usecols=['isbn', 'title', 'author','y','p','img2','img'],\n",
        "#     dtype={'isbn': 'str', 'title': 'str', 'author': 'str','y':'str','p':'str','img2':'str','img':'str'})\n",
        "# # pickle.dump(booksdb,open('booksdb.pkl','wb'))\n",
        "# # pickle.dump(titles2,open('titles.pkl','wb'))\n",
        "# # booksdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# import os\n",
        "# import time\n",
        "\n",
        "\n",
        "# output_directory = \"filess\"\n",
        "\n",
        "# if not os.path.exists(output_directory):\n",
        "#     os.makedirs(output_directory)\n",
        "\n",
        "# def fetch_book_description(isbn):\n",
        "#     url = f\"https://openlibrary.org/isbn/{isbn}\"\n",
        "\n",
        "#     response = requests.get(url)\n",
        "\n",
        "#     # Check if the request was successful (status code 200)\n",
        "#     if response.status_code == 200:\n",
        "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "#         description_element = soup.find('div', {'class': 'book-description'})\n",
        "\n",
        "#         if description_element:\n",
        "#             description = description_element.get_text(strip=True)\n",
        "#             return description\n",
        "\n",
        "#     return None\n",
        "# def descextract(isbn_list):\n",
        "#     for isbn in isbn_list:\n",
        "#         description = fetch_book_description(isbn)\n",
        "#         if description:\n",
        "#             filename = f\"{isbn}.txt\"\n",
        "#             with open(os.path.join(output_directory, filename), \"w\", encoding=\"utf-8\") as file:\n",
        "#                 file.write(description)\n",
        "#                 print(f\"Saved description for ISBN {isbn} to {filename}\")\n",
        "#         else:\n",
        "#             print(f\"Description not found for ISBN {isbn}\")\n",
        "#         time.sleep(0.7)\n",
        "\n",
        "#     print(\"Done\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
