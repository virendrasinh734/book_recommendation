{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended books for  Murder of a Sleeping Beauty (Scumble River Mysteries (Paperback)) (['0451205480']):\n",
      " Murder of a Sleeping Beauty (Scumble River Mysteries (Paperback)) (['0451205480'])\n",
      "Belgrave Square (['0449222276', '0449906787'])\n",
      "Greenwich Killing Time (['0425104974', '0970238304'])\n",
      "Tombstone Courage: A Joanna Brady Mystery (['0380765462'])\n",
      "SS/GB (['0345284941'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import json\n",
    "data_dir = \"./ddeess\"\n",
    "with open(\"ind_to_book.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    ind_to_book = json.load(json_file)\n",
    "def preprocess_text(text):\n",
    "    tokens = text.lower().split()  \n",
    "    return tokens\n",
    "documents = []\n",
    "file_paths = [os.path.join(data_dir, f\"{i}.txt\") for i in range(13629)]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        description = file.read()\n",
    "        tokens = preprocess_text(description)\n",
    "        tag = os.path.basename(file_path).split(\".\")[0]\n",
    "        document = TaggedDocument(words=tokens, tags=[tag])\n",
    "        documents.append(document)\n",
    "\n",
    "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=10)\n",
    "model.build_vocab(documents)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "k = 10  \n",
    "book_vectors = [model.dv[f\"{i}\"] for i in range(13629)]  \n",
    "nbrs = NearestNeighbors(n_neighbors=k, metric=\"cosine\").fit(book_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_index = 12475\n",
    "\n",
    "distances, indices = nbrs.kneighbors([book_vectors[user_input_index]])\n",
    "\n",
    "recommended_book_indices = indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended books for Three Act Tragedy (Hercule Poirot Mysteries (Paperback)) (['0425091805']):\n",
      "Three Act Tragedy (Hercule Poirot Mysteries (Paperback))\n",
      "12475\n",
      "The Passenger\n",
      "11385\n",
      "Sudden Mischief\n",
      "9192\n",
      "Caught In The Act\n",
      "1907\n",
      "Bite (Love Spell)\n",
      "1336\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recommended books for {ind_to_book[str(user_input_index)]['title']} ({ind_to_book[str(user_input_index)]['isbns']}):\")\n",
    "for book_index in recommended_book_indices:\n",
    "    print(f\"{ind_to_book[str(book_index)]['title']}\")\n",
    "    print(book_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to read local cache '/home/virendrasinh10/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/downloader.py:219\u001b[0m, in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# We need io.open here because Py2 open doesn't support encoding keyword\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39mopen(cache_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding) \u001b[39mas\u001b[39;00m fin:\n\u001b[1;32m    220\u001b[0m         \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mload(fin)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/virendrasinh10/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/virendrasinh10/odin/book_recommendation/descmodel.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/virendrasinh10/odin/book_recommendation/descmodel.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/virendrasinh10/odin/book_recommendation/descmodel.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownloader\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mapi\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/virendrasinh10/odin/book_recommendation/descmodel.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mglove-wiki-gigaword-100\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/virendrasinh10/odin/book_recommendation/descmodel.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m data_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./ddeess\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/virendrasinh10/odin/book_recommendation/descmodel.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mind_to_book.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m json_file:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/downloader.py:490\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Download (if needed) dataset/model and load it to memory (unless `return_path` is set).\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \n\u001b[1;32m    488\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m _create_base_dir()\n\u001b[0;32m--> 490\u001b[0m file_name \u001b[39m=\u001b[39m _get_filename(name)\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncorrect model/corpus name\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/downloader.py:426\u001b[0m, in \u001b[0;36m_get_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_filename\u001b[39m(name):\n\u001b[1;32m    413\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Retrieve the filename of the dataset/model.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m     information \u001b[39m=\u001b[39m info()\n\u001b[1;32m    427\u001b[0m     corpora \u001b[39m=\u001b[39m information[\u001b[39m'\u001b[39m\u001b[39mcorpora\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    428\u001b[0m     models \u001b[39m=\u001b[39m information[\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/downloader.py:268\u001b[0m, in \u001b[0;36minfo\u001b[0;34m(name, show_only_latest, name_only)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfo\u001b[39m(name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, show_only_latest\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    229\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Provide the information related to model/dataset.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     information \u001b[39m=\u001b[39m _load_info()\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         corpora \u001b[39m=\u001b[39m information[\u001b[39m'\u001b[39m\u001b[39mcorpora\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/downloader.py:222\u001b[0m, in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mload(fin)\n\u001b[1;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[39m'\u001b[39m\u001b[39munable to read local cache \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m during fallback, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mconnect to the Internet and retry\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m cache_path\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: unable to read local cache '/home/virendrasinh10/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import json\n",
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "data_dir = \"./ddeess\"\n",
    "\n",
    "with open(\"ind_to_book.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    ind_to_book = json.load(json_file)\n",
    "\n",
    "k = 5  \n",
    "\n",
    "def get_document_vector(book_index):\n",
    "    with open(os.path.join(data_dir, f\"{book_index}.txt\"), \"r\", encoding=\"utf-8\") as file:\n",
    "        description = file.read()\n",
    "\n",
    "    title = ind_to_book.get(str(book_index), {}).get(\"title\", \"\")\n",
    "\n",
    "    combined_text = title + \" \" + description\n",
    "\n",
    "    return model.infer_vector(combined_text.lower().split())\n",
    "\n",
    "user_input_index = 0  \n",
    "\n",
    "user_input_vector = get_document_vector(user_input_index)\n",
    "\n",
    "book_vectors = [get_document_vector(i) for i in range(13629)]\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=k, metric=\"cosine\").fit(book_vectors)\n",
    "distances, indices = nbrs.kneighbors([user_input_vector])\n",
    "\n",
    "recommended_book_indices = indices[0]\n",
    "\n",
    "print(f\"Recommended books for {ind_to_book.get(str(user_input_index), {}).get('title', 'Unknown Title')} ({ind_to_book.get(str(user_input_index), {}).get('isbns', 'Unknown ISBNs')}):\")\n",
    "for book_index in recommended_book_indices:\n",
    "    book_title = ind_to_book.get(str(book_index), {}).get(\"title\", \"Unknown Title\")\n",
    "    book_isbns = ind_to_book.get(str(book_index), {}).get(\"isbns\", \"Unknown ISBNs\")\n",
    "    similarity = 1 - distances[recommended_book_indices.tolist().index(book_index)]\n",
    "    print(f\"{book_title} ({book_isbns}), Similarity: {similarity}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
